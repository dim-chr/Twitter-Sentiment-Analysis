# -*- coding: utf-8 -*-
"""Sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PeQk4RlIBWH4_rb2gL33qX9nA8geZjRa
"""

import pandas as pd
import nltk
nltk.download('stopwords')
import string
import re
import sys
import pickle as pkl
from nltk.corpus import stopwords

# 1 Question

#make a list of english stopwords
stopwords = nltk.corpus.stopwords.words("english")

#read csv file
df = pd.read_pickle('eclass_all_with_sentiment_v2.pkl')

#set to lower case letters
df = df.apply(lambda x: x.astype(str).str.lower())

#remove stopwords
df["text"] = df["text"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))
#remove URLs
df["text"] = df["text"].apply(lambda x: re.split('https:\/\/.*', str(x))[0])
#remove hashtags
df["text"] = df["text"].apply(lambda x: re.sub("#[A-Za-z0-9_]+","", str(x)))
#remove punctuation
df["text"] = df["text"].str.translate(str.maketrans('','',string.punctuation))

#remove emojies
df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))

# Spliting dataframe

max_rows = len(df)
train_size = int(len(df)*0.8)
test_size = len(df) - train_size;

print(max_rows , " " , train_size , " " , test_size)

tf_train = df.iloc[:train_size]
tf_test = df.iloc[train_size:]

print( len(tf_train) , " " , len(tf_test))

tf_train.to_csv('train.tsv',  index = False , sep="\t")
tf_test.to_csv('test.tsv', index = False, sep="\t")

# 2_i Question
import matplotlib.pyplot as plt

pos = 0 
neg = 0
neut = 0

last_column = df.iloc[: , -1]
for val in last_column:
  if(val == "pos"):
    pos+=1
  elif(val == "neg"):
    neg+=1
  elif(val == "neu"):
    neut+=1

# creating the dataset
data = {'Positive':pos, 'Negative':neg, 'Neutral':neut}
sentiment = list(data.keys())
values = list(data.values())
  
fig = plt.figure(figsize = (8, 6))
 
# creating the bar plot
plt.bar(sentiment[0], values[0], color ='green', width = 0.5)
plt.bar(sentiment[1], values[1], color ='red', width = 0.5)
plt.bar(sentiment[2], values[2], color ='blue', width = 0.5)

plt.xlabel("Sentiment")
plt.ylabel("Values")
plt.title("Sentiment Allocation")

plt.grid(linestyle='-.', linewidth=0.5 , color='silver', fillstyle='full')
plt.show()

import collections
import matplotlib.pyplot as plt

max_display = 10

words = []
for row in df["text"]:
  word = row.split();
  words.extend(word)

counter = collections.Counter(words)
most_common_words = counter.most_common(max_display)
common_dict = dict(most_common_words)

# Figure Size
fig, ax = plt.subplots(figsize =(16, 9))
 
# Horizontal Bar Plot
ax.barh(list(common_dict.keys()), list(common_dict.values()))
 
# Remove axes splines
for s in ['top', 'bottom', 'left', 'right']:
    ax.spines[s].set_visible(False)
 
# Remove x, y Ticks
ax.xaxis.set_ticks_position('none')
ax.yaxis.set_ticks_position('none')
 
# Add padding between axes and labels
ax.xaxis.set_tick_params(pad = 5)
ax.yaxis.set_tick_params(pad = 10)
 
# Add x, y gridlines
ax.grid(b = True, color ='grey',
        linestyle ='-.', linewidth = 0.5,
        alpha = 0.2)
 
# Show higher values first
ax.invert_yaxis()
 
# Add annotation to bars
for i in ax.patches:
    plt.text(i.get_width()+0.2, i.get_y()+0.5,
             str(round((i.get_width()), 2)),
             fontsize = 10, fontweight ='bold',
             color ='grey')
 
ax.set_title('Most Common Words', loc ='left', )

plt.show()